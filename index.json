[{"authors":["admin"],"categories":null,"content":"I am a PhD candidate at Dyson Robotics Lab at Imperial College London. I am supervised by Dr. Leutenegger. Before that I earned my M.Sc. in Artificial Intelligence and Robotics at La Sapienza in Rome and did my undergrad in Computer Engineering at Roma Tre in Rome.\nMy research interest is at the intersection between 3D Reconstruction and Deep Learning. I am currently exploring how to augment traditional 3D reconstruction and mapping algorithm with Deep Learning.\nWhenever I am not at my desk I spend time climbing and camping around rainy UK.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://localhost:1313/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD candidate at Dyson Robotics Lab at Imperial College London. I am supervised by Dr. Leutenegger. Before that I earned my M.Sc. in Artificial Intelligence and Robotics at La Sapienza in Rome and did my undergrad in Computer Engineering at Roma Tre in Rome.\nMy research interest is at the intersection between 3D Reconstruction and Deep Learning. I am currently exploring how to augment traditional 3D reconstruction and mapping algorithm with Deep Learning.","tags":null,"title":"Andrea Nicastro","type":"authors"},{"authors":["Andrea Nicastro","Ronald Clark","Stefan Leutenegger"],"categories":[],"content":"","date":1565195480,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565195480,"objectID":"b4c1efd0a9a9fa14c6af5532248f491a","permalink":"http://localhost:1313/publication/xsection/","publishdate":"2019-08-07T16:31:20Z","relpermalink":"/publication/xsection/","section":"publication","summary":"Detailed 3D reconstruction is an important challenge with application to robotics, augmented and virtual reality, which has seen impressive progress throughout the past years. Advancements were driven by the availability of depth cameras (RGB-D), as well as increased compute power, e.g. in the form of GPUs -- but also thanks to inclusion of machine learning in the process. Here, we propose X-Section, an RGB-D 3D reconstruction approach that leverages deep learning to make object-level predictions about thicknesses that can be readily integrated into a volumetric multi-view fusion process, where we propose an extension to the popular KinectFusion approach. In essence, our method allows to complete shapes in general indoor scenes behind what is sensed by the RGB-D camera, which may be crucial e.g. for robotic manipulation tasks or efficient scene exploration. Predicting object thicknesses rather than volumes allows us to work with comparably high spatial resolution without exploding memory and training data requirements on the employed Convolutional Neural Networks. In a series of qualitative and quantitative evaluations, we demonstrate how we accurately predict object thickness and reconstruct general 3D scenes containing multiple objects.","tags":["xsection"],"title":"X-Section: Cross-section Prediction for Enhanced RGB-D Fusion","type":"publication"}]